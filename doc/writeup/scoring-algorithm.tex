\section{Scoring Algorithm}
\label{sec:scoring}

% TODO: High level description
Many recommendation systems today can be classified as either content-based
systems or collaborative filtering systems
(http://infolab.stanford.edu/~ullman/mmds/ch9.pdf). Content-based systems seek
to offer you suggestions based on items a user has already given some form of
feedback on, while collaborative filtering systems search social graphs to find
people who would have similar ``taste'' to a given user and make recommendations
based on these similar users. Usually, these types of recommendations present
themselves as ``items like X'' or ``similar users also purchased/likes X,''
respectively. Since Agent is responding to specific queries rather than drawing
similarities between users, we decided that a content-based approach was more
appropriate.

In using a content-based system, we had to design a scoring algorithm in order
to rank different candidates in response to the query. At a high level, we
identified the identified the scoring criteria as follows:
\begin{enumerate}
\item Frequency of search keys in friend's activity
\item Frequency of related terms in friend's activity
\item Priority to ``specialized'' terms
\item Priority for more search keys matched
\end{enumerate}
where friend's activity includes the friend's posts, check-ins, interest,
\todo{[TODO: fill in]}
and ``related terms'' are defined as the topic and domain of a term as given by the Freebase API.

Term Frequency Inverse-Document Frequency (TF-IDF) \todo{[Citation needed]} is a
well-established metric for determining how relevant a given term is to a
document. It is based off of a ``relative frequency'' count of the search key
and is scaled by how common the word is in general. However, based on this
measure, a document can only be highly relevant for a few topics, whereas we
believe some people are simply more equipped to answer more questions than
others, based on the size of their knowledge set. Therefore, for criteria 1 and
2, we opted for an absolute frequency instead of a relative frequency.
Specifically, we looked at the number of times that the search keys (or related
terms) appear in the person's Facebook activity.

A concept that we did adopt from TF-IDF is the idea of prioritizing
``specialized'' terms. The motivation behind this is two-fold: \begin{enumerate}
\item Words that are used more commonly will otherwise dominate the score, and
thus the counts of these words should be offset
\item We suspect that the more ``specialized'' search keys are more definitive
of the user's query.
\end{enumerate}

We calculate ``specialized'' words by how frequently they have appeared in past
searches or in the activity of any user in our database.

As for the fourth criteria, we seek to recommend ``experts'' based on how well
they match a query, so if only part of a query is matched, we consider that to
be less good of a match than a user who matches all parts of a query. If the
user was only interested in a subset of their query, they simply could have
searched for that subset.

Given that our service is in essence a ``friend filter,'' these criteria were
selected based on what a user expects this service to be doing. There is very
little emphasis on ``discoverability.'' We are simply helping the user parse
through a lot of data and find the friends that match their search query.

In terms of choosing the scaling factors, we had the option to use a
machine-learning approach to optimize over a certain condition, but there is no
really sensible condition for which we can rank to relative importance of these
various criteria, especially because we are not collecting any ratings values
from the users. It is also generally difficult to claim the effectiveness of a
recommendation system strictly using a quantitative measure. Thus, we selected
our parameters through testing runs using different parameter values for our
algorithm and choosing the set of parameters for which the users had the most
positive response. Although, in the future, it might be interesting to adjust
the parameters.


% TODO: SQL

\todo{BLi}
